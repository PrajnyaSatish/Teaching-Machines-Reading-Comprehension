{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import simplejson as json\n",
    "from pprint import pprint as pp\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    \"\"\"Returns the tokens of a sequece\"\"\"\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/SciQ dataset/train.json', 'r') as rf:\n",
    "    train = json.load(rf)\n",
    "with open('data/SciQ dataset/test.json', 'r') as rf:\n",
    "    test = json.load(rf)\n",
    "with open('data/SciQ dataset/valid.json', 'r') as rf:\n",
    "    valid = json.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def preprocess(data_in):\n",
    "    q = []\n",
    "    s = []\n",
    "    o = []\n",
    "    for sample in data_in:\n",
    "        question = sample['question']\n",
    "        support = sample['support']\n",
    "        option1 = (sample['distractor1'], 0)\n",
    "        option2 = (sample['distractor2'], 0)\n",
    "        option3 = (sample['distractor3'], 0)\n",
    "        option4 = (sample['correct_answer'], 1)\n",
    "        options = [option1, option2, option3, option4]\n",
    "        shuffle(options)\n",
    "        print(options)\n",
    "        q.append(question)\n",
    "        s.append(support)\n",
    "        o.append(options)\n",
    "    return q, s, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('viruses', 0), ('mesophilic organisms', 1), ('protozoa', 0), ('gymnosperms', 0)]\n",
      "[('muon effect', 0), ('centrifugal effect', 0), ('tropical effect', 0), ('coriolis effect', 1)]\n",
      "[('reactive', 0), ('unbalanced', 0), ('exothermic', 1), ('endothermic', 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['What type of organism is commonly used in preparation of foods such as cheese and yogurt?',\n",
       "  'What phenomenon makes global winds blow northeast to southwest or the reverse in the northern hemisphere and northwest to southeast or the reverse in the southern hemisphere?',\n",
       "  'Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always what?'],\n",
       " ['Mesophiles grow best in moderate temperature, typically between 25°C and 40°C (77°F and 104°F). Mesophiles are often found living in or on the bodies of humans or other animals. The optimal growth temperature of many pathogenic mesophiles is 37°C (98°F), the normal human body temperature. Mesophilic organisms have important uses in food preparation, including cheese, yogurt, beer and wine.',\n",
       "  'Without Coriolis Effect the global winds would blow north to south or south to north. But Coriolis makes them blow northeast to southwest or the reverse in the Northern Hemisphere. The winds blow northwest to southeast or the reverse in the southern hemisphere.',\n",
       "  'Summary Changes of state are examples of phase changes, or phase transitions. All phase changes are accompanied by changes in the energy of a system. Changes from a more-ordered state to a less-ordered state (such as a liquid to a gas) areendothermic. Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always exothermic. The conversion of a solid to a liquid is called fusion (or melting). The energy required to melt 1 mol of a substance is its enthalpy of fusion (ΔHfus). The energy change required to vaporize 1 mol of a substance is the enthalpy of vaporization (ΔHvap). The direct conversion of a solid to a gas is sublimation. The amount of energy needed to sublime 1 mol of a substance is its enthalpy of sublimation (ΔHsub) and is the sum of the enthalpies of fusion and vaporization. Plots of the temperature of a substance versus heat added or versus heating time at a constant rate of heating are calledheating curves. Heating curves relate temperature changes to phase transitions. A superheated liquid, a liquid at a temperature and pressure at which it should be a gas, is not stable. A cooling curve is not exactly the reverse of the heating curve because many liquids do not freeze at the expected temperature. Instead, they form a supercooled liquid, a metastable liquid phase that exists below the normal melting point. Supercooled liquids usually crystallize on standing, or adding a seed crystal of the same or another substance can induce crystallization.'],\n",
       " [[('viruses', 0),\n",
       "   ('mesophilic organisms', 1),\n",
       "   ('protozoa', 0),\n",
       "   ('gymnosperms', 0)],\n",
       "  [('muon effect', 0),\n",
       "   ('centrifugal effect', 0),\n",
       "   ('tropical effect', 0),\n",
       "   ('coriolis effect', 1)],\n",
       "  [('reactive', 0), ('unbalanced', 0), ('exothermic', 1), ('endothermic', 0)]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocab(input_data):\n",
    "    vocab_list = set()\n",
    "    for sample in input_data:\n",
    "        s_t = tokenize(sample['support'])\n",
    "        q_t = tokenize(sample['question'])\n",
    "        d1_t = tokenize(sample['distractor1'])\n",
    "        d2_t = tokenize(sample['distractor2'])\n",
    "        d3_t = tokenize(sample['distractor3'])\n",
    "        a_t = tokenize(sample['correct_answer'])\n",
    "        vocab_list |= set(s_t+q_t+d1_t+d2_t+d3_t+a_t)\n",
    "    vocab_list=sorted(vocab_list)\n",
    "    vocab_size = len(vocab_list)+3\n",
    "    vocab = dict((c,i+2) for i,c in enumerate(vocab_list))\n",
    "    print(\"Vocab ready\")\n",
    "    return vocab_list, vocab_size, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(input_sent, vocab, vocab_list):\n",
    "    tokenized = tokenize(input_sent)\n",
    "    vectorized = []\n",
    "    for w in tokenized:\n",
    "        if w in vocab_list:\n",
    "            vectorized.append(vocab[w])\n",
    "        else:\n",
    "            vectorized.append(vocab['UNK_ID'])\n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_input(data, vocab, vocab_size, support_maxlen, query_maxlen):\n",
    "    qs = []\n",
    "    sps = []\n",
    "    ans = []\n",
    "    dis1s = []\n",
    "    dis2s = []\n",
    "    dis3s = []\n",
    "    dis4s = []\n",
    "    for _,sample in enumerate(data):\n",
    "        q_vect = get_vectors(sample['question'], vocab, vocab_list)\n",
    "        support_vect = get_vectors(sample['support'], vocab , vocab_list)\n",
    "        ans_tokens = tokenize(sample['correct_answer'])\n",
    "        answer_vect = np.zeros(vocab_size)\n",
    "        for w in ans_tokens:\n",
    "            if w in vocab_list:\n",
    "                answer_vect[vocab[w]]=1\n",
    "            else:\n",
    "                answer_vect[vocab['UNK_ID']]=1\n",
    "                \n",
    "        answer_vect = np.transpose(answer_vect)\n",
    "                    \n",
    "                                \n",
    "        distractor1_vect = get_vectors(sample['distractor1'], vocab , vocab_list)\n",
    "        distractor2_vect = get_vectors(sample['distractor2'], vocab , vocab_list)\n",
    "        distractor3_vect = get_vectors(sample['distractor3'], vocab , vocab_list)\n",
    "        distractor4_vect = get_vectors(sample['correct_answer'], vocab , vocab_list)\n",
    "        qs.append(q_vect)\n",
    "        sps.append(support_vect)\n",
    "        ans.append(answer_vect)\n",
    "        dis1s.append(distractor1_vect)\n",
    "        dis2s.append(distractor2_vect)\n",
    "        dis3s.append(distractor3_vect)\n",
    "        dis4s.append(distractor4_vect)\n",
    "    return(pad_sequences(qs, maxlen=query_maxlen),\\\n",
    "           pad_sequences(sps, maxlen=support_maxlen),\\\n",
    "           pad_sequences(dis1s, maxlen=query_maxlen),\\\n",
    "           pad_sequences(dis2s, maxlen=query_maxlen),\\\n",
    "           pad_sequences(dis3s, maxlen=query_maxlen),\\\n",
    "           pad_sequences(dis4s, maxlen=query_maxlen),\\\n",
    "           np.array(ans)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize_input(train[:5], vocab, vocab_list, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM/EMBED/SUPPORT/QUERY=<class 'keras.layers.recurrent.LSTM'>,300,300,100\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE = 300\n",
    "Q_HIDDEN_SIZE = 100\n",
    "S_HIDDEN_SIZE = 300\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "print('LSTM/EMBED/SUPPORT/QUERY={0},{1},{2},{3}'.format(LSTM,\n",
    "                                                    EMBED_SIZE,\n",
    "                                                    S_HIDDEN_SIZE,\n",
    "                                                    Q_HIDDEN_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab ready\n"
     ]
    }
   ],
   "source": [
    "vocab_list, vocab_size, vocab = createVocab(train+valid+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,s,d1,d2,d3, d4,a = vectorize_input(train[:3], vocab, vocab_size, S_HIDDEN_SIZE, Q_HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = layers.Input(shape=(S_HIDDEN_SIZE,), dtype='int32')\n",
    "encoded_support = layers.Embedding(vocab_size, EMBED_SIZE)(support)\n",
    "encoded_support = layers.Dropout(0.3)(encoded_support)\n",
    "support_LSTM = LSTM(EMBED_SIZE)(encoded_support)\n",
    "support_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(support_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32')\n",
    "encoded_question = layers.Embedding(vocab_size, EMBED_SIZE)(question)\n",
    "encoded_question = layers.Dropout(0.3)(encoded_question)\n",
    "question_LSTM = LSTM(EMBED_SIZE)(encoded_question)\n",
    "question_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(question_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor1 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32')\n",
    "encoded_distractor1 = layers.Embedding(vocab_size, EMBED_SIZE)(distractor1)\n",
    "encoded_distractor1 = layers.Dropout(0.3)(encoded_distractor1)\n",
    "distractor1_LSTM = LSTM(EMBED_SIZE)(encoded_distractor1)\n",
    "distractor1_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(distractor1_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor2 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32')\n",
    "encoded_distractor2 = layers.Embedding(vocab_size, EMBED_SIZE)(distractor2)\n",
    "encoded_distractor2 = layers.Dropout(0.3)(encoded_distractor2)\n",
    "distractor2_LSTM = LSTM(EMBED_SIZE)(encoded_distractor2)\n",
    "distractor2_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(distractor2_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor3 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32')\n",
    "encoded_distractor3 = layers.Embedding(vocab_size, EMBED_SIZE)(distractor3)\n",
    "encoded_distractor3 = layers.Dropout(0.3)(encoded_distractor3)\n",
    "distractor3_LSTM = LSTM(EMBED_SIZE)(encoded_distractor3)\n",
    "distractor3_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(distractor3_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor4 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32')\n",
    "encoded_distractor4 = layers.Embedding(vocab_size, EMBED_SIZE)(distractor4)\n",
    "encoded_distractor4 = layers.Dropout(0.3)(encoded_distractor4)\n",
    "distractor4_LSTM = LSTM(EMBED_SIZE)(encoded_distractor4)\n",
    "distractor4_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(distractor4_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-73327ecd1f66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmatch_LSTM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEMBED_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmatch_LSTM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_LSTM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_LSTM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[1;34m'kernel_constraint'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m             \u001b[1;34m'bias_constraint'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m         }\n\u001b[0m\u001b[0;32m    882\u001b[0m         \u001b[0mbase_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m   2961\u001b[0m     \"\"\"Softplus of a tensor.\n\u001b[0;32m   2962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2963\u001b[1;33m     \u001b[1;31m# Arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2964\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "MatchLSTM_layer = layers.add([support_LSTM, question_LSTM])\n",
    "rankerLSTM_layer = layers.add([distractor1_LSTM, distractor2_LSTM, distractor3_LSTM, distractor4_LSTM])\n",
    "merged = layers.add([MatchLSTM_layer , rankerLSTM_layer])\n",
    "match_LSTM = LSTM(EMBED_SIZE)(merged)\n",
    "match_LSTM = layers.Dropout(0.3)(match_LSTM)\n",
    "predictions = layers.Dense(vocab_size, activation='softmax')(match_LSTM)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-1e0dbea4a95a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msupport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model.compile(optimizer='adam',\n\u001b[0;32m      3\u001b[0m              \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m              metrics=['accuracy'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model([support, question], predictions)\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training')\n",
    "model.fit([s,q], a,\n",
    "         batch_size=BATCH_SIZE,\n",
    "         epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
