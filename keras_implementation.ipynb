{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "from numpy import newaxis\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    \"\"\"Returns the tokens of a sequece\"\"\"\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/SciQ dataset/train.json', 'r') as rf:\n",
    "    train = json.load(rf)\n",
    "with open('data/SciQ dataset/test.json', 'r') as rf:\n",
    "    test = json.load(rf)\n",
    "with open('data/SciQ dataset/valid.json', 'r') as rf:\n",
    "    valid = json.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def preprocess(data_in):\n",
    "    q = []\n",
    "    s = []\n",
    "    o = []\n",
    "    l = []\n",
    "    for sample in data_in:\n",
    "        question = sample['question']\n",
    "        support = sample['support']\n",
    "        option1 = (sample['distractor1'], -1)\n",
    "        option2 = (sample['distractor2'], -1)\n",
    "        option3 = (sample['distractor3'], -1)\n",
    "        option4 = (sample['correct_answer'], 1)\n",
    "        options = [option1, option2, option3, option4]\n",
    "        random.seed(1204)\n",
    "        random.shuffle(options)\n",
    "        q.append(question)\n",
    "        s.append(support)\n",
    "        o.append(tuple(op for op,_ in options))\n",
    "        l.append(tuple(label for _l, label in options))\n",
    "    X = {'questions': q, 'support': s, 'options': o}\n",
    "    return X, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocab(input_data):\n",
    "    vocab_list = set()\n",
    "    for sample in input_data:\n",
    "        s_t = tokenize(sample['support'])\n",
    "        q_t = tokenize(sample['question'])\n",
    "        d1_t = tokenize(sample['distractor1'])\n",
    "        d2_t = tokenize(sample['distractor2'])\n",
    "        d3_t = tokenize(sample['distractor3'])\n",
    "        a_t = tokenize(sample['correct_answer'])\n",
    "        vocab_list |= set(s_t+q_t+d1_t+d2_t+d3_t+a_t)\n",
    "    vocab_list=sorted(vocab_list)\n",
    "    vocab_size = len(vocab_list)+3\n",
    "    vocab = dict((c,i+2) for i,c in enumerate(vocab_list))\n",
    "    print(\"Vocab ready\")\n",
    "    return vocab_list, vocab_size, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab ready\n"
     ]
    }
   ],
   "source": [
    "vocab_list, vocab_size, vocab = createVocab(train+valid+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(input_sent, vocab, vocab_list):\n",
    "    tokenized = tokenize(input_sent)\n",
    "    vectorized = []\n",
    "    for w in tokenized:\n",
    "        if w in vocab_list:\n",
    "            vectorized.append(vocab[w])\n",
    "        else:\n",
    "            vectorized.append(vocab['UNK_ID'])\n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_input(X, y, vocab, vocab_size, support_maxlen, query_maxlen):\n",
    "    op1 = []\n",
    "    op2 = []\n",
    "    op3 = []\n",
    "    op4 = []\n",
    "    l1 = []; l2 = []; l3 = []; l4 = []\n",
    "    for label_list in y:\n",
    "        l1.append(label_list[0])\n",
    "        l2.append(label_list[1])\n",
    "        l3.append(label_list[2])\n",
    "        l4.append(label_list[3])\n",
    "    labels = [np.array(l1),np.array(l2),np.array(l3),np.array(l4)]\n",
    "    qs = [get_vectors(sent, vocab, vocab_list) for sent in X['questions']]\n",
    "    sps = [get_vectors(sent, vocab, vocab_list) for sent in X['support']]\n",
    "    for sample_options in X['options']:\n",
    "        op1.append(get_vectors(sample_options[0], vocab, vocab_list))\n",
    "        op2.append(get_vectors(sample_options[1], vocab, vocab_list))\n",
    "        op3.append(get_vectors(sample_options[2], vocab, vocab_list))\n",
    "        op4.append(get_vectors(sample_options[3], vocab, vocab_list))\n",
    "    return(pad_sequences(qs, maxlen=query_maxlen),\\\n",
    "           pad_sequences(sps, maxlen=support_maxlen),\\\n",
    "           pad_sequences(op1, maxlen=query_maxlen),\\\n",
    "           pad_sequences(op2, maxlen=query_maxlen),\\\n",
    "           pad_sequences(op3, maxlen=query_maxlen),\\\n",
    "           pad_sequences(op4, maxlen=query_maxlen),\\\n",
    "           labels\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM/EMBED/SUPPORT/QUERY=<class 'keras.layers.recurrent.LSTM'>,300,300,60\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE = 300\n",
    "Q_HIDDEN_SIZE = 100\n",
    "S_HIDDEN_SIZE = 300\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "print('LSTM/EMBED/SUPPORT/QUERY={0},{1},{2},{3}'.format(LSTM,\n",
    "                                                    EMBED_SIZE,\n",
    "                                                    S_HIDDEN_SIZE,\n",
    "                                                    Q_HIDDEN_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = layers.Input(shape=(S_HIDDEN_SIZE,), dtype='int32', name='support_input')\n",
    "encoded_support = layers.Embedding(vocab_size, EMBED_SIZE)(support)\n",
    "encoded_support = layers.Dropout(0.3)(encoded_support)\n",
    "support_LSTM = LSTM(EMBED_SIZE)(encoded_support)\n",
    "support_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(support_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32', name='question_input')\n",
    "encoded_question = layers.Embedding(vocab_size, EMBED_SIZE)(question)\n",
    "encoded_question = layers.Dropout(0.3)(encoded_question)\n",
    "question_LSTM = LSTM(EMBED_SIZE)(encoded_question)\n",
    "question_LSTM = layers.RepeatVector(S_HIDDEN_SIZE)(question_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_3/truediv:0\", shape=(?, 300, 300), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "MatchLSTM_layer = layers.add([support_LSTM, question_LSTM])\n",
    "MatchLSTM_layer = layers.Dropout(0.5)(MatchLSTM_layer)\n",
    "MatchLSTM_layer = LSTM(EMBED_SIZE, return_sequences=True)(MatchLSTM_layer)\n",
    "MatchLSTM_layer = layers.Dense(S_HIDDEN_SIZE, activation = 'softmax')(MatchLSTM_layer)\n",
    "print(MatchLSTM_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_match(distractor, MatchLSTM_layer, option_num, S_HIDDEN_SIZE, Q_HIDDEN_SIZE):\n",
    "    encoded_distractor = layers.Embedding(vocab_size, EMBED_SIZE)(distractor)\n",
    "    encoded_distractor = layers.Dropout(0.3)(encoded_distractor)\n",
    "    distractor_LSTM = LSTM(EMBED_SIZE)(encoded_distractor)\n",
    "    added = layers.add([MatchLSTM_layer, distractor_LSTM])\n",
    "    option_Match = layers.Dropout(0.3)(added)\n",
    "    option_Match = LSTM(1)(option_Match)\n",
    "    option_Match = layers.Dense(1, activation='tanh', name='op_{0}'.format(str(option_num)))(option_Match)\n",
    "    return option_Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor1 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32', name='Option1_Input')\n",
    "distractor2 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32', name='Option2_Input')\n",
    "distractor3 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32', name='Option3_Input')\n",
    "distractor4 = layers.Input(shape=(Q_HIDDEN_SIZE,), dtype='int32', name='Option4_Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "option1_Match = get_option_match(distractor1,MatchLSTM_layer,1, S_HIDDEN_SIZE,Q_HIDDEN_SIZE)\n",
    "option2_Match = get_option_match(distractor2,MatchLSTM_layer,2, S_HIDDEN_SIZE,Q_HIDDEN_SIZE)\n",
    "option3_Match = get_option_match(distractor3,MatchLSTM_layer,3, S_HIDDEN_SIZE,Q_HIDDEN_SIZE)\n",
    "option4_Match = get_option_match(distractor4,MatchLSTM_layer,4, S_HIDDEN_SIZE,Q_HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "support_input (InputLayer)      (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 300, 300)     9234600     support_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 60, 300)      9234600     question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 300, 300)     0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 60, 300)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  (None, 300)          721200      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 300)          721200      dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 300, 300)     0           lstm_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_6 (RepeatVector)  (None, 300, 300)     0           lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 300, 300)     0           repeat_vector_5[0][0]            \n",
      "                                                                 repeat_vector_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Option1_Input (InputLayer)      (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Option2_Input (InputLayer)      (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Option3_Input (InputLayer)      (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Option4_Input (InputLayer)      (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 300, 300)     0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 60, 300)      9234600     Option1_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 60, 300)      9234600     Option2_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 60, 300)      9234600     Option3_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 60, 300)      9234600     Option4_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 300, 300)     721200      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 60, 300)      0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 60, 300)      0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 60, 300)      0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 60, 300)      0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300, 300)     90300       lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 300)          721200      dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 300)          721200      dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_40 (LSTM)                  (None, 300)          721200      dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_42 (LSTM)                  (None, 300)          721200      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 300, 300)     0           dense_3[0][0]                    \n",
      "                                                                 lstm_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 300, 300)     0           dense_3[0][0]                    \n",
      "                                                                 lstm_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 300, 300)     0           dense_3[0][0]                    \n",
      "                                                                 lstm_40[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 300, 300)     0           dense_3[0][0]                    \n",
      "                                                                 lstm_42[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 300, 300)     0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 300, 300)     0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 300, 300)     0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 300, 300)     0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_37 (LSTM)                  (None, 1)            1208        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (None, 1)            1208        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_41 (LSTM)                  (None, 1)            1208        dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_43 (LSTM)                  (None, 1)            1208        dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "op_1 (Dense)                    (None, 1)            2           lstm_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op_2 (Dense)                    (None, 1)            2           lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op_3 (Dense)                    (None, 1)            2           lstm_41[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "op_4 (Dense)                    (None, 1)            2           lstm_43[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 60,551,140\n",
      "Trainable params: 60,551,140\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model([support, question, distractor1, distractor2, distractor3, distractor4], \\\n",
    "              [option1_Match, option2_Match, option3_Match, option4_Match])\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='Final_Model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='squared_hinge',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=['op_1_loss','op_2_loss','op_3_loss','op_4_loss'],\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "X,y = preprocess(train)\n",
    "q,s,d1,d2,d3, d4,a = vectorize_input(X, y, vocab, vocab_size, S_HIDDEN_SIZE, Q_HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"\\models\\weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='op_1_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11679/11679 [==============================] - 279s 24ms/step - loss: 1.9889 - op_1_loss: 0.8009 - op_2_loss: 0.0543 - op_3_loss: 0.4176 - op_4_loss: 0.7161 - op_1_acc: 0.0000e+00 - op_2_acc: 0.9447 - op_3_acc: 0.0000e+00 - op_4_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "11679/11679 [==============================] - 268s 23ms/step - loss: 1.2647 - op_1_loss: 0.5326 - op_2_loss: 0.0162 - op_3_loss: 0.2491 - op_4_loss: 0.4667 - op_1_acc: 0.0000e+00 - op_2_acc: 1.0000 - op_3_acc: 0.5287 - op_4_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "11679/11679 [==============================] - 268s 23ms/step - loss: 0.8570 - op_1_loss: 0.3624 - op_2_loss: 0.0121 - op_3_loss: 0.1666 - op_4_loss: 0.3160 - op_1_acc: 0.0000e+00 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.6040 - op_1_loss: 0.2550 - op_2_loss: 0.0093 - op_3_loss: 0.1174 - op_4_loss: 0.2224 - op_1_acc: 0.4630 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 0.8685\n",
      "Epoch 5/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.4427 - op_1_loss: 0.1862 - op_2_loss: 0.0073 - op_3_loss: 0.0866 - op_4_loss: 0.1626 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 6/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.3360 - op_1_loss: 0.1406 - op_2_loss: 0.0059 - op_3_loss: 0.0663 - op_4_loss: 0.1232 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 7/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.2626 - op_1_loss: 0.1094 - op_2_loss: 0.0048 - op_3_loss: 0.0523 - op_4_loss: 0.0961 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 8/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.2104 - op_1_loss: 0.0873 - op_2_loss: 0.0040 - op_3_loss: 0.0422 - op_4_loss: 0.0769 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 9/50\n",
      "11679/11679 [==============================] - 266s 23ms/step - loss: 0.1721 - op_1_loss: 0.0711 - op_2_loss: 0.0034 - op_3_loss: 0.0348 - op_4_loss: 0.0628 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 10/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.1432 - op_1_loss: 0.0590 - op_2_loss: 0.0029 - op_3_loss: 0.0292 - op_4_loss: 0.0522 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 11/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.1209 - op_1_loss: 0.0496 - op_2_loss: 0.0025 - op_3_loss: 0.0248 - op_4_loss: 0.0440 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 12/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.1034 - op_1_loss: 0.0423 - op_2_loss: 0.0022 - op_3_loss: 0.0213 - op_4_loss: 0.0376 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 13/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0893 - op_1_loss: 0.0365 - op_2_loss: 0.0020 - op_3_loss: 0.0185 - op_4_loss: 0.0324 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 14/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0779 - op_1_loss: 0.0317 - op_2_loss: 0.0017 - op_3_loss: 0.0162 - op_4_loss: 0.0283 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 15/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0685 - op_1_loss: 0.0278 - op_2_loss: 0.0016 - op_3_loss: 0.0143 - op_4_loss: 0.0248 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 16/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0606 - op_1_loss: 0.0246 - op_2_loss: 0.0014 - op_3_loss: 0.0127 - op_4_loss: 0.0219 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 17/50\n",
      "11679/11679 [==============================] - 266s 23ms/step - loss: 0.0540 - op_1_loss: 0.0218 - op_2_loss: 0.0013 - op_3_loss: 0.0113 - op_4_loss: 0.0195 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 18/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0483 - op_1_loss: 0.0195 - op_2_loss: 0.0011 - op_3_loss: 0.0102 - op_4_loss: 0.0175 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 19/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0435 - op_1_loss: 0.0175 - op_2_loss: 0.0010 - op_3_loss: 0.0092 - op_4_loss: 0.0157 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 20/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0393 - op_1_loss: 0.0158 - op_2_loss: 9.4764e-04 - op_3_loss: 0.0083 - op_4_loss: 0.0142 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 21/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0356 - op_1_loss: 0.0143 - op_2_loss: 8.6755e-04 - op_3_loss: 0.0076 - op_4_loss: 0.0129 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 22/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0325 - op_1_loss: 0.0131 - op_2_loss: 7.9649e-04 - op_3_loss: 0.0069 - op_4_loss: 0.0117 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 23/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0296 - op_1_loss: 0.0119 - op_2_loss: 7.3316e-04 - op_3_loss: 0.0063 - op_4_loss: 0.0107 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 24/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0272 - op_1_loss: 0.0109 - op_2_loss: 6.7646e-04 - op_3_loss: 0.0058 - op_4_loss: 0.0098 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 25/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0249 - op_1_loss: 0.0100 - op_2_loss: 6.2551e-04 - op_3_loss: 0.0053 - op_4_loss: 0.0090 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 26/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0230 - op_1_loss: 0.0092 - op_2_loss: 5.7956e-04 - op_3_loss: 0.0049 - op_4_loss: 0.0083 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 27/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0212 - op_1_loss: 0.0085 - op_2_loss: 5.3797e-04 - op_3_loss: 0.0045 - op_4_loss: 0.0076 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 28/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0196 - op_1_loss: 0.0078 - op_2_loss: 5.0023e-04 - op_3_loss: 0.0042 - op_4_loss: 0.0071 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 29/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0182 - op_1_loss: 0.0073 - op_2_loss: 4.6587e-04 - op_3_loss: 0.0039 - op_4_loss: 0.0065 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 30/50\n",
      "11679/11679 [==============================] - 266s 23ms/step - loss: 0.0169 - op_1_loss: 0.0067 - op_2_loss: 4.3450e-04 - op_3_loss: 0.0036 - op_4_loss: 0.0061 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 31/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0157 - op_1_loss: 0.0063 - op_2_loss: 4.0580e-04 - op_3_loss: 0.0034 - op_4_loss: 0.0056 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 32/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0146 - op_1_loss: 0.0058 - op_2_loss: 3.7948e-04 - op_3_loss: 0.0031 - op_4_loss: 0.0053 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 33/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0136 - op_1_loss: 0.0054 - op_2_loss: 3.5528e-04 - op_3_loss: 0.0029 - op_4_loss: 0.0049 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11679/11679 [==============================] - 266s 23ms/step - loss: 0.0127 - op_1_loss: 0.0051 - op_2_loss: 3.3300e-04 - op_3_loss: 0.0027 - op_4_loss: 0.0046 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 35/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0119 - op_1_loss: 0.0047 - op_2_loss: 3.1244e-04 - op_3_loss: 0.0026 - op_4_loss: 0.0043 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 36/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0111 - op_1_loss: 0.0044 - op_2_loss: 2.9343e-04 - op_3_loss: 0.0024 - op_4_loss: 0.0040 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 37/50\n",
      "11679/11679 [==============================] - 266s 23ms/step - loss: 0.0104 - op_1_loss: 0.0041 - op_2_loss: 2.7582e-04 - op_3_loss: 0.0023 - op_4_loss: 0.0037 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 38/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0098 - op_1_loss: 0.0039 - op_2_loss: 2.5949e-04 - op_3_loss: 0.0021 - op_4_loss: 0.0035 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 39/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0092 - op_1_loss: 0.0036 - op_2_loss: 2.4433e-04 - op_3_loss: 0.0020 - op_4_loss: 0.0033 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 40/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0086 - op_1_loss: 0.0034 - op_2_loss: 2.3022e-04 - op_3_loss: 0.0019 - op_4_loss: 0.0031 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 41/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0081 - op_1_loss: 0.0032 - op_2_loss: 2.1708e-04 - op_3_loss: 0.0018 - op_4_loss: 0.0029 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 42/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0076 - op_1_loss: 0.0030 - op_2_loss: 2.0482e-04 - op_3_loss: 0.0017 - op_4_loss: 0.0027 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 43/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0072 - op_1_loss: 0.0029 - op_2_loss: 1.9338e-04 - op_3_loss: 0.0016 - op_4_loss: 0.0026 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 44/50\n",
      "11679/11679 [==============================] - 266s 23ms/step - loss: 0.0068 - op_1_loss: 0.0027 - op_2_loss: 1.8269e-04 - op_3_loss: 0.0015 - op_4_loss: 0.0024 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 45/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0064 - op_1_loss: 0.0025 - op_2_loss: 1.7268e-04 - op_3_loss: 0.0014 - op_4_loss: 0.0023 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 46/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0060 - op_1_loss: 0.0024 - op_2_loss: 1.6330e-04 - op_3_loss: 0.0013 - op_4_loss: 0.0022 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 47/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0057 - op_1_loss: 0.0023 - op_2_loss: 1.5451e-04 - op_3_loss: 0.0012 - op_4_loss: 0.0020 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 48/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0054 - op_1_loss: 0.0021 - op_2_loss: 1.4627e-04 - op_3_loss: 0.0012 - op_4_loss: 0.0019 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 49/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0051 - op_1_loss: 0.0020 - op_2_loss: 1.3852e-04 - op_3_loss: 0.0011 - op_4_loss: 0.0018 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n",
      "Epoch 50/50\n",
      "11679/11679 [==============================] - 267s 23ms/step - loss: 0.0048 - op_1_loss: 0.0019 - op_2_loss: 1.3124e-04 - op_3_loss: 0.0010 - op_4_loss: 0.0017 - op_1_acc: 1.0000 - op_2_acc: 1.0000 - op_3_acc: 1.0000 - op_4_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0414338c88>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([s,q, d1,d2,d3,d4], [a[0],a[1], a[2], a[3]],\n",
    "         batch_size=128,\n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 331ms/step\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid = preprocess(valid)\n",
    "vq,vs,vd1,vd2,vd3,vd4,va = vectorize_input(X_valid, y_valid, vocab, vocab_size, S_HIDDEN_SIZE, Q_HIDDEN_SIZE)\n",
    "loss = model.evaluate([vs,vq, vd1,vd2,vd3,vd4], [va[0],va[1], va[2], va[3]],\n",
    "                         batch_size=BATCH_SIZE)\n",
    "# print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_op1,p_op2, p_op3, p_op4 = model.predict([vs,vq, vd1,vd2,vd3,vd4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_50_epochs_bs_128.h5\")\n",
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_50_epochs_bs_128.json\", \"w\") as wf:\n",
    "    wf.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y[:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [[o1,o2,o3,o4] for o1,o2,o3,o4 in zip(p_op1,p_op2,p_op3,p_op4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(highest_val_correct_acc(predictions,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
